{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd51551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class NakliLLM:\n",
    "\n",
    "  def __init__(self):\n",
    "    print('LLM created')\n",
    "\n",
    "  def predict(self, prompt):\n",
    "\n",
    "    response_list = [\n",
    "        'Delhi is the capital of India',\n",
    "        'IPL is a cricket league',\n",
    "        'AI stands for Artificial Intelligence'\n",
    "    ]\n",
    "\n",
    "    return {'response': random.choice(response_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b79506d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NakliPromptTemplate:\n",
    "\n",
    "  def __init__(self, template, input_variables):\n",
    "    self.template = template\n",
    "    self.input_variables = input_variables\n",
    "\n",
    "  def format(self, input_dict):\n",
    "    return self.template.format(**input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dca64c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = NakliPromptTemplate(\n",
    "    template='Write a {length} poem about {topic}',\n",
    "    input_variables=['length', 'topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb68a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.format({'length':'short','topic':'india'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0acdf040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM created\n"
     ]
    }
   ],
   "source": [
    "llm = NakliLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d266457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'IPL is a cricket league'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b16f535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NakliLLMChain:\n",
    "\n",
    "  def __init__(self, llm, prompt):\n",
    "    self.llm = llm\n",
    "    self.prompt = prompt\n",
    "\n",
    "  def run(self, input_dict):\n",
    "\n",
    "    final_prompt = self.prompt.format(input_dict)\n",
    "    result = self.llm.predict(final_prompt)\n",
    "\n",
    "    return result['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4aff826",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = NakliPromptTemplate(\n",
    "    template='Write a {length} poem about {topic}',\n",
    "    input_variables=['length', 'topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b247dfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM created\n"
     ]
    }
   ],
   "source": [
    "llm = NakliLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb60759",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = NakliLLMChain(llm, template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd9a69b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Delhi is the capital of India'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run({'length':'short', 'topic': 'india'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In LangChain, Runnables are a unified interface for anything that can be executed—whether that’s a prompt, a model call, a chain, or even a sequence of transformations.\n",
    "# They’re part of LangChain’s newer architecture (post-v0.1) that replaces the old Chain abstraction with something more flexible and composable.\n",
    "\n",
    "# Key idea\n",
    "# A Runnable is an object with a .invoke(), .batch(), and .stream() method that you can run synchronously, in batches, or as a stream.\n",
    "# It can represent:\n",
    "# A single LLM call\n",
    "# A prompt template\n",
    "# A retriever\n",
    "# A chain of other Runnables\n",
    "\n",
    "# Why they exist\n",
    "# Before Runnables, LangChain’s Chain interface was rigid and mostly synchronous.\n",
    "# Runnables:\n",
    "# Give one standard API for all components (models, retrievers, tools, transformations).\n",
    "# Support sync, async, batch, and streaming out of the box.\n",
    "# Make composition easier (RunnableSequence, .pipe())."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
